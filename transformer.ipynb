{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08541793776693105\n",
      "0.1553053413944201\n",
      "0.211780010992391\n",
      "0.25670304362714064\n",
      "0.29170800412175063\n",
      "0.3182269135873643\n",
      "0.33751339319871965\n",
      "0.3506632656610074\n",
      "0.35863288533512117\n",
      "0.3622554397324456\n",
      "0.3622554397324456\n",
      "0.3592615931230865\n",
      "0.35381823565152454\n",
      "0.34639547546303096\n",
      "0.33739819038606916\n",
      "0.32717400279861253\n",
      "0.3160203436122961\n",
      "0.30419070508135454\n",
      "0.2919001715427139\n",
      "0.27933030769637696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.205472348859357"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "pv = 745\n",
    "r = 0.10\n",
    "for i in range(1,21):\n",
    "    a =i*(70/((1+r)**i))/pv\n",
    "    print(a)\n",
    "    sum = sum + a\n",
    "sum + (1000/((1+r)**20))/pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2615.339366124404"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_a = 0.6\n",
    "std_r = 0.4\n",
    "corr = 0.9\n",
    "rf = 0\n",
    "q_a = 10000\n",
    "q_r = 13500\n",
    "\n",
    "v = math.sqrt((std_a*q_a)**2 + (std_r*q_r)**2 - 2*q_r*q_a*corr*std_a*std_r)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x136ef1590>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "st = np.linspace(0,120,100)\n",
    "x_call_long = 90\n",
    "x_put_long = 80\n",
    "x_call_short = 90\n",
    "x_put_short = 50\n",
    "def long_call(st):\n",
    "    return max(st-x_call_long,0)\n",
    "def long_put(st):\n",
    "    return max(x_put_long-st,0)\n",
    "def short_call(st):\n",
    "    return -max(st-x_call_short,0)\n",
    "def short_put(st):\n",
    "    return -max(x_put_short-st,0)\n",
    "long_call_payoff = np.vectorize(long_call)(st)\n",
    "long_put_payoff = np.vectorize(long_put)(st)\n",
    "short_call_payoff = np.vectorize(short_call)(st)\n",
    "short_put_payoff = np.vectorize(short_put)(st)\n",
    "plt.plot(st,long_put_payoff-25)\n",
    "plt.plot(st,short_put_payoff+5)\n",
    "plt.plot(st,long_put_payoff+short_put_payoff-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -1\n",
       "1        -1\n",
       "2        -1\n",
       "3        -1\n",
       "4        -1\n",
       "         ..\n",
       "72860    21\n",
       "72861    19\n",
       "72862    17\n",
       "72863    12\n",
       "72864    11\n",
       "Name: sn_value, Length: 72865, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import requests\n",
    "\n",
    "names = ['year', 'month', 'day', 'dec_year', 'sn_value',\n",
    "         'sn_error', 'obs_num', 'unused1']\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"SN_d_tot_V2.0.csv\",sep=';',header=None,names=names,na_values=' -1',)\n",
    "df['sn_value'] = df['sn_value'].fillna(df['sn_value'].mean())\n",
    "df['sn_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71.],\n",
       "       [75.],\n",
       "       [80.],\n",
       "       ...,\n",
       "       [17.],\n",
       "       [12.],\n",
       "       [11.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "df = pd.read_csv(\n",
    "    \"SN_d_tot_V2.0.csv\",sep=';',header=None,names=names,na_values=' -1',)\n",
    "start_id = max(df[df['obs_num'] == 0].index.tolist()) + 1\n",
    "df = df[start_id:].copy()\n",
    "df['sn_value'] = df['sn_value'].astype(float)\n",
    "df_train = df[df['year'] < 2000]\n",
    "df_test = df[df['year'] >= 2000]\n",
    "\n",
    "spots_train = df_train['sn_value'].to_numpy().reshape(-1, 1)\n",
    "spots_test = df_test['sn_value'].to_numpy().reshape(-1, 1)\n",
    "spots_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequenced already!\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_b/4lj1bh0s4473m5xx061k14lc0000gn/T/ipykernel_89301/30439550.py:84: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  if getattr(torch, \"has_mps\", False)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data=np.random.randn(1000, 4), columns=['a', 'b','c','d'])\n",
    "df['sum'] = df.sum(axis=1) + np.random.rand()\n",
    "df_train = df[:df.shape[0]*4//5]\n",
    "df_test = df[df.shape[0]*4//5:]\n",
    "\n",
    "y = 'sum'\n",
    "\n",
    "spots_train = df_train[y].to_numpy().reshape(-1, 1)\n",
    "spots_test = df_test[y].to_numpy().reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "spots_train = scaler.fit_transform(spots_train).flatten().tolist()\n",
    "spots_test = scaler.transform(spots_test).flatten().tolist()\n",
    "\n",
    "# Sequence Data Preparation\n",
    "SEQUENCE_SIZE = 10\n",
    "\n",
    "def to_sequences(seq_size, obs):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(obs) - seq_size):\n",
    "        window = obs[i:(i + seq_size)]\n",
    "        after_window = obs[i + seq_size]\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "    return torch.tensor(x, dtype=torch.float32).view(-1, seq_size, 1), torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "x_train, y_train = to_sequences(SEQUENCE_SIZE, spots_train)\n",
    "x_test, y_test = to_sequences(SEQUENCE_SIZE, spots_test)\n",
    "\n",
    "print(\"sequenced already!\")\n",
    "\n",
    "\n",
    "# Setup data loaders for batch\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_loader.batch_size\n",
    "\n",
    "# Positional Encoding for Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "# Model definition using Transformer\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2, dropout=0.2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.decoder(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if getattr(torch, \"has_mps\", False)\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "model = TransformerModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Validation Loss: 1.0724\n",
      "Epoch 2/1000, Validation Loss: 1.0631\n",
      "Epoch 3/1000, Validation Loss: 1.0554\n",
      "Epoch 4/1000, Validation Loss: 1.0747\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Desktop/ucla_python_lab/applied project/transformer.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(x_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, y_batch)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Validation\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "epochs = 1000\n",
    "early_stop_count = 0\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        early_stop_count = 0\n",
    "    else:\n",
    "        early_stop_count += 1\n",
    "\n",
    "    if early_stop_count >= 5:\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        predictions.extend(outputs.squeeze().tolist())\n",
    "\n",
    "rmse = np.sqrt(np.mean((scaler.inverse_transform(np.array(predictions).reshape(-1, 1)) - scaler.inverse_transform(y_test.numpy().reshape(-1, 1)))**2))\n",
    "print(f\"Score (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(None, 800, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), slice(None, 800, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Desktop/ucla_python_lab/applied project/transformer.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mindex \u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_train \u001b[39m=\u001b[39m df[:,:df\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]\u001b[39m*\u001b[39;49m\u001b[39m4\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m5\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_test \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m5\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3660\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3660\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[1;32m   3661\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:5737\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5733\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   5734\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5735\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5736\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5737\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), slice(None, 800, None))"
     ]
    }
   ],
   "source": [
    "df['id'] = df.index +1\n",
    "df['sum'] = df['sum'].astype(float)\n",
    "threshold_train_test = df.shape[0]*4//5\n",
    "df_train = df[:,:df.shape[0]*4//5]\n",
    "df_test = df[df.shape[0]*4//5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71.],\n",
       "       [75.],\n",
       "       [80.],\n",
       "       ...,\n",
       "       [17.],\n",
       "       [12.],\n",
       "       [11.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_b/4lj1bh0s4473m5xx061k14lc0000gn/T/ipykernel_80305/3304198112.py:83: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  if getattr(torch, \"has_mps\", False)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "df = pd.read_csv(\n",
    "    \"SN_d_tot_V2.0.csv\",sep=';',header=None,names=names,na_values=' -1',)\n",
    "start_id = max(df[df['obs_num'] == 0].index.tolist()) + 1\n",
    "df = df[start_id:].copy()\n",
    "df['sn_value'] = df['sn_value'].astype(float)\n",
    "df_train = df[df['year'] < 2000]\n",
    "df_test = df[df['year'] >= 2000]\n",
    "\n",
    "spots_train = df_train['sn_value'].to_numpy().reshape(-1, 1)\n",
    "spots_test = df_test['sn_value'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "spots_train = scaler.fit_transform(spots_train).flatten().tolist()\n",
    "spots_test = scaler.transform(spots_test).flatten().tolist()\n",
    "\n",
    "# Sequence Data Preparation\n",
    "SEQUENCE_SIZE = 10\n",
    "\n",
    "def to_sequences(seq_size, obs):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(obs) - seq_size):\n",
    "        window = obs[i:(i + seq_size)]\n",
    "        after_window = obs[i + seq_size]\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "    return torch.tensor(x, dtype=torch.float32).view(-1, seq_size, 1), torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "x_train, y_train = to_sequences(SEQUENCE_SIZE, spots_train)\n",
    "x_test, y_test = to_sequences(SEQUENCE_SIZE, spots_test)\n",
    "\n",
    "# Setup data loaders for batch\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_loader.batch_size\n",
    "\n",
    "# Positional Encoding for Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "# Model definition using Transformer\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2, dropout=0.2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.decoder(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if getattr(torch, \"has_mps\", False)\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "model = TransformerModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Validation Loss: 0.0497\n",
      "Epoch 2/1000, Validation Loss: 0.0475\n",
      "Epoch 3/1000, Validation Loss: 0.0690\n",
      "Epoch 4/1000, Validation Loss: 0.0407\n",
      "Epoch 5/1000, Validation Loss: 0.0514\n",
      "Epoch 6/1000, Validation Loss: 0.0427\n",
      "Epoch 7/1000, Validation Loss: 0.0405\n",
      "Epoch 8/1000, Validation Loss: 0.0382\n",
      "Epoch 9/1000, Validation Loss: 0.0577\n",
      "Epoch 10/1000, Validation Loss: 0.0360\n",
      "Epoch 11/1000, Validation Loss: 0.0361\n",
      "Epoch 12/1000, Validation Loss: 0.0402\n",
      "Epoch 13/1000, Validation Loss: 0.0370\n",
      "Epoch 14/1000, Validation Loss: 0.0357\n",
      "Epoch 15/1000, Validation Loss: 0.0364\n",
      "Epoch 16/1000, Validation Loss: 0.0386\n",
      "Epoch 17/1000, Validation Loss: 0.0391\n",
      "Epoch 18/1000, Validation Loss: 0.0355\n",
      "Epoch 19/1000, Validation Loss: 0.0394\n",
      "Epoch 20/1000, Validation Loss: 0.0381\n",
      "Epoch 21/1000, Validation Loss: 0.0387\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Desktop/ucla_python_lab/applied project/transformer.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Validation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     adam(\n\u001b[1;32m    164\u001b[0m         params_with_grad,\n\u001b[1;32m    165\u001b[0m         grads,\n\u001b[1;32m    166\u001b[0m         exp_avgs,\n\u001b[1;32m    167\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    168\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    169\u001b[0m         state_steps,\n\u001b[1;32m    170\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    172\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    173\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    177\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    178\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    179\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    180\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    181\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    182\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m func(params,\n\u001b[1;32m    312\u001b[0m      grads,\n\u001b[1;32m    313\u001b[0m      exp_avgs,\n\u001b[1;32m    314\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    315\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    316\u001b[0m      state_steps,\n\u001b[1;32m    317\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    318\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    319\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    320\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    321\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    322\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    323\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    324\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    325\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    326\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    327\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adam.py:385\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    384\u001b[0m exp_avg\u001b[39m.\u001b[39mlerp_(grad, \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m--> 385\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39;49maddcmul_(grad, grad\u001b[39m.\u001b[39;49mconj(), value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta2)\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n\u001b[1;32m    388\u001b[0m     step \u001b[39m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "epochs = 1000\n",
    "early_stop_count = 0\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        early_stop_count = 0\n",
    "    else:\n",
    "        early_stop_count += 1\n",
    "\n",
    "    if early_stop_count >= 5:\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        predictions.extend(outputs.squeeze().tolist())\n",
    "\n",
    "rmse = np.sqrt(np.mean((scaler.inverse_transform(np.array(predictions).reshape(-1, 1)) - scaler.inverse_transform(y_test.numpy().reshape(-1, 1)))**2))\n",
    "print(f\"Score (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dydx', 'umami', 'gns', 'bifi', 'looks', 'rbn', 'rdt', 'dpx',\n",
       "       'gmx', 'crv', 'snx'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv(\"MergedFinalData3.0.csv\")\n",
    "#for protocol  in data['protocol'].unique():\n",
    "#    print(data[data['protocol'] == protocol]['TVL'].mean(),protocol)\n",
    "data['protocol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TVL</th>\n",
       "      <th>protocol</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>88</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>70</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>98</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>96</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>87</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>39</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>48</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>57</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>58</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TVL protocol  year\n",
       "0    54      rdt  2007\n",
       "1    40      rdt  2008\n",
       "2    91      rdt  2009\n",
       "3    48      rbn  2010\n",
       "4    13     dydx  2011\n",
       "5    27      rbn  2012\n",
       "6    45      rdt  2013\n",
       "7    45      rbn  2014\n",
       "8    64      rdt  2015\n",
       "9    46      rbn  2016\n",
       "10    0      rbn  2017\n",
       "11   88     dydx  2018\n",
       "12   19     dydx  2019\n",
       "13   70     dydx  2020\n",
       "14   11      rdt  2021\n",
       "15   98      rdt  2022\n",
       "16   96      rbn  2023\n",
       "17   32      rbn  2024\n",
       "18   25     dydx  2025\n",
       "19   87      rdt  2026\n",
       "20   46     dydx  2027\n",
       "21    9      rbn  2028\n",
       "22   18      rdt  2029\n",
       "23   39      rbn  2030\n",
       "24   36     dydx  2031\n",
       "25   39      rbn  2032\n",
       "26   48      rdt  2033\n",
       "27   57     dydx  2034\n",
       "28   14     dydx  2035\n",
       "29   58      rbn  2036"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 30\n",
    "test_df = pd.DataFrame({'TVL':np.random.randint(0,100,size= n),'protocol':np.random.choice(['dydx','rbn','rdt'],n),'year': np.array([i for i in range(2022-n//2,2022+n//2)])})\n",
    "df = test_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[1;32m   1349\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   1350\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1286\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1281\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1041\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m \n\u001b[1;32m   1045\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 979\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    980\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1458\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     server_hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[0;32m-> 1458\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context\u001b[39m.\u001b[39;49mwrap_socket(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock,\n\u001b[1;32m   1459\u001b[0m                                       server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    512\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[1;32m    518\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[1;32m    519\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[1;32m    520\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[1;32m    521\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[1;32m    522\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    523\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    524\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[1;32m    525\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1108\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1108\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1109\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1379\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1379\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1380\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Desktop/ucla_python_lab/applied project/transformer.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Desktop/ucla_python_lab/applied%20project/transformer.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://github.com/BACCHUS2333/homework3.github.io/blob/main/2023-05-11\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m2010-53-32zhihu_hot.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:716\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    713\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    715\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    717\u001b[0m     path_or_buf,\n\u001b[1;32m    718\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    719\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    720\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    721\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    725\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:368\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    367\u001b[0m req_info \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[39m=\u001b[39mstorage_options)\n\u001b[0;32m--> 368\u001b[0m \u001b[39mwith\u001b[39;00m urlopen(req_info) \u001b[39mas\u001b[39;00m req:\n\u001b[1;32m    369\u001b[0m     content_encoding \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    370\u001b[0m     \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    371\u001b[0m         \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:270\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   1392\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"https://github.com/BACCHUS2333/homework3.github.io/blob/main/2023-05-11%2010-53-32zhihu_hot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dydx', 'umami', 'gns', 'bifi', 'looks', 'rbn', 'rdt', 'dpx',\n",
       "       'gmx', 'crv', 'snx'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "url = \"https://raw.githubusercontent.com/BACCHUS2333/homework3.github.io/main/frax.csv\"\n",
    "url = \"https://raw.githubusercontent.com/BACCHUS2333/homework2.github.io/main/MergedFinalData3.0.csv\"\n",
    "s=requests.get(url).content\n",
    "c=pd.read_csv(io.StringIO(s.decode('utf-8'))).iloc[:,1:]\n",
    "c.head()\n",
    "c['protocol'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TVL</th>\n",
       "      <th>protocol</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>35</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>77</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>45</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>35</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>49</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>59</td>\n",
       "      <td>rdt</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>98</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>68</td>\n",
       "      <td>rbn</td>\n",
       "      <td>2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100</td>\n",
       "      <td>dydx</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TVL protocol  year\n",
       "0    96      rbn  2007\n",
       "1    52      rbn  2008\n",
       "2    33      rbn  2009\n",
       "3    42      rdt  2010\n",
       "4    28      rdt  2011\n",
       "5    61     dydx  2012\n",
       "6    91     dydx  2013\n",
       "7    75      rdt  2014\n",
       "8    73      rdt  2015\n",
       "9    53      rbn  2016\n",
       "10   75     dydx  2017\n",
       "11   14     dydx  2018\n",
       "12   19      rdt  2019\n",
       "13   80      rbn  2020\n",
       "14   29      rbn  2021\n",
       "15   35      rbn  2022\n",
       "16   28      rbn  2023\n",
       "17   53      rbn  2024\n",
       "18   73     dydx  2025\n",
       "19   77      rdt  2026\n",
       "20   85      rbn  2027\n",
       "21   45      rdt  2028\n",
       "22   35      rbn  2029\n",
       "23   61      rbn  2030\n",
       "24   49     dydx  2031\n",
       "25   11     dydx  2032\n",
       "26    6      rdt  2033\n",
       "27   59      rdt  2034\n",
       "28   98      rbn  2035\n",
       "29   68      rbn  2036\n",
       "30  100     dydx  2022"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
